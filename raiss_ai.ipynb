{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "402b8eb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T10:46:10.998787Z",
     "start_time": "2025-04-14T10:46:10.995659Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install -U langgraph transformers langsmith langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14fd6e2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:54:25.548364Z",
     "start_time": "2025-04-14T15:54:23.875900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA_API_KEY: ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_nvidia import ChatNVIDIA\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"NVIDIA_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd4a44fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:54:30.825712Z",
     "start_time": "2025-04-14T15:54:26.595273Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityavinodh/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9362fbe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:57:49.127280Z",
     "start_time": "2025-04-14T15:57:49.124139Z"
    }
   },
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e10ddafe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:56:51.342948Z",
     "start_time": "2025-04-14T15:56:51.332806Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def load_documents_from_json(directory_path):\n",
    "    \"\"\"Load documents from a directory containing JSON files.\"\"\"\n",
    "    documents = []\n",
    "    for file_path in Path(directory_path).glob(\"*.json\"):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                content = json.load(f)\n",
    "                text = content.get(\"Scraped Text\", \"\")\n",
    "                # Decode any escape sequences like \\u2013 (en dash) in the text\n",
    "                text = text.encode('utf-8').decode('unicode_escape')\n",
    "                metadata = {\n",
    "                    \"source\": content.get(\"URL location\", \"\"),\n",
    "                    \"last_modified\": content.get(\"Last modification date\", \"\"),\n",
    "                    \"change_frequency\": content.get(\"Change frequency\", \"\"),\n",
    "                    \"priority\": content.get(\"Priority\", \"\")\n",
    "                }\n",
    "                if text.strip():  # Only include documents with non-empty text\n",
    "                    # Generate a unique ID for each document, e.g., using the file name\n",
    "                    document_id = str(file_path.name)  # Using file name as the ID\n",
    "                    documents.append(Document(page_content=text, metadata=metadata, id=document_id))\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {file_path.name}: {e}\")\n",
    "                continue  # Skip this file and move to the next one\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2104ddb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:54:31.094211Z",
     "start_time": "2025-04-14T15:54:31.091544Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def update_vectorstore_from_scraped():\n",
    "    global vectorstore, embeddings\n",
    "\n",
    "    print(\"Loading documents from scraped_data_json...\")\n",
    "    new_documents = load_documents_from_json(\"scraped_data_json\")\n",
    "\n",
    "    if not new_documents:\n",
    "        print(\"No documents found.\")\n",
    "        return \"No documents found.\"\n",
    "\n",
    "    try:\n",
    "        vectorstore = FAISS.from_documents(new_documents, embeddings)\n",
    "        vectorstore.save_local(vectorDB_name)\n",
    "        print(\"Vectorstore updated from scraped JSON data.\")\n",
    "        return \"Success\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error while updating vectorstore: {e}\")\n",
    "        return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09b250a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:41:49.140860Z",
     "start_time": "2025-04-14T16:41:49.135940Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_and_search_docs(user_input, k=20):\n",
    "    global vectorstore, embeddings\n",
    "    if not vectorstore:\n",
    "        load_vector_database(vectorDB_name)\n",
    "\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    docs = retriever.get_relevant_documents(user_input)\n",
    "\n",
    "    print(f\"\\n🔍 Query: {user_input}\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        metadata_str = doc.metadata if hasattr(doc, 'metadata') else \"No metadata\"\n",
    "        print(f\"\\n📄 doc_{i} (source: {metadata_str}):\\n{doc.page_content[:300]}...\")\n",
    "\n",
    "    return {f\"doc_{i}\": d.page_content for i, d in enumerate(docs)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d048a3a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:54:34.041260Z",
     "start_time": "2025-04-14T15:54:33.951356Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityavinodh/anaconda3/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/_common.py:212: UserWarning: Found meta/llama-3.3-70b-instruct in available_models, but type is unknown and inference may fail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "llm = ChatNVIDIA(base_url=\"https://integrate.api.nvidia.com/v1\", model=\"meta/llama-3.3-70b-instruct\")\n",
    "def check_relevance_node(state):\n",
    "    user_question = state[\"user_input\"]\n",
    "    docs = state[\"docs\"]  # dict of key -> content\n",
    "\n",
    "    relevant_docs = {}\n",
    "\n",
    "    for key, content in docs.items():\n",
    "        prompt = f\"\"\"\n",
    "Question or email:\n",
    "\"{user_question}\"\n",
    "\n",
    "Document content:\n",
    "{content}\n",
    "\n",
    "Does this content answer the question directly?\n",
    "Respond with your clear justification first, followed by \"YES\" or \"NO\" only on the last line.\n",
    "If absolutely uncertain, respond \"NO\". If slightly certain, respond \"YES\"\n",
    "\"\"\"\n",
    "        try:\n",
    "            resp = llm.invoke(prompt)  # returns AIMessage\n",
    "            answer = resp.content.strip()\n",
    "            # Check if the answer is YES or NO and act accordingly\n",
    "            last_line = answer.split('\\n')[-1].strip().upper()\n",
    "            if last_line == \"YES\":\n",
    "                relevant_docs[key] = content\n",
    "                print(f\"Document '{key}' is relevant!\")\n",
    "            else:\n",
    "                print(f\"Document '{key}' is not relevant.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] {key} relevance check failed:\", e)\n",
    "\n",
    "    # Store the relevant docs in the state for further use\n",
    "    state[\"relevant_docs\"] = relevant_docs\n",
    "    print(f\"Checked {len(docs)} docs. Found {len(relevant_docs)} relevant.\")\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "259dad68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:54:39.875762Z",
     "start_time": "2025-04-14T15:54:39.795250Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityavinodh/anaconda3/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/_common.py:212: UserWarning: Found meta/llama-3.3-70b-instruct in available_models, but type is unknown and inference may fail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "llm = ChatNVIDIA(base_url=\"https://integrate.api.nvidia.com/v1\", model=\"meta/llama-3.3-70b-instruct\")\n",
    "\n",
    "def build_prompt_node(state):\n",
    "    user_question = state[\"user_input\"]\n",
    "    relevant_docs = state.get(\"relevant_docs\", {})\n",
    "\n",
    "    if not relevant_docs:\n",
    "        print(\"No relevant documents found. Skipping final prompt generation.\")\n",
    "        state[\"final_response\"] = \"Sorry, I couldn't find a relevant answer in the provided documents.\"\n",
    "        return state\n",
    "\n",
    "    combined_context = \"\\n\\n---\\n\\n\".join(\n",
    "        f\"Document {i+1}:\\n{content}\" for i, content in enumerate(relevant_docs.values())\n",
    "    )\n",
    "\n",
    "    final_prompt = f\"\"\"\n",
    "You are an intelligent assistant.\n",
    "\n",
    "Here is a question from the user:\n",
    "\"{user_question}\"\n",
    "\n",
    "Here are relevant pieces of context from various documents:\n",
    "{combined_context}\n",
    "\n",
    "Based on the above content, provide a complete and helpful answer to the user's question.\n",
    "Be as specific and concise. If the content is not enough, say so clearly.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = llm.invoke(final_prompt)\n",
    "        final_answer = response.content.strip()\n",
    "        state[\"final_response\"] = final_answer\n",
    "    except Exception as e:\n",
    "        print(\"[Error] Failed to generate final response:\", e)\n",
    "        state[\"final_response\"] = \"An error occurred while generating the answer.\"\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e7f941",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:54:41.822535Z",
     "start_time": "2025-04-14T15:54:41.819427Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_answer_node(state):\n",
    "    final_answer = state.get(\"final_response\", None)\n",
    "\n",
    "    if not final_answer:\n",
    "        print(\"No final response available to return.\")\n",
    "        state[\"answer\"] = \"Sorry, I couldn't generate an answer at this time.\"\n",
    "    else:\n",
    "        state[\"answer\"] = final_answer\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89062587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:54:52.746118Z",
     "start_time": "2025-04-14T15:54:42.661907Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"get_initial_docs\", lambda state: {**state, \"docs\": load_and_search_docs(state[\"user_input\"])})\n",
    "\n",
    "builder.add_node(\"check_relevance\", check_relevance_node)\n",
    "builder.add_node(\"build_prompt\", build_prompt_node)\n",
    "builder.add_node(\"generate_answer\", generate_answer_node)\n",
    "\n",
    "builder.set_entry_point(\"get_initial_docs\")\n",
    "builder.add_edge(\"get_initial_docs\", \"check_relevance\")\n",
    "builder.add_edge(\"check_relevance\", \"build_prompt\")\n",
    "builder.add_edge(\"build_prompt\", \"generate_answer\")\n",
    "\n",
    "builder.set_finish_point(\"generate_answer\")\n",
    "\n",
    "graph = builder.compile()\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c35d957e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:00:35.572234Z",
     "start_time": "2025-04-14T15:57:53.165709Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/c3rg13j54bdfj4dsnvyvgsyh0000gn/T/ipykernel_50628/1119709352.py:10: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the vector database from chunked documents.\n"
     ]
    }
   ],
   "source": [
    "# Define global variables for embeddings and model names\n",
    "vectorstore = None\n",
    "embeddings = None\n",
    "model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "vectorDB_name = \"raiss_site\"\n",
    "\n",
    "def initialize_embeddings():\n",
    "    \"\"\"Initialize the embedding model with remote code trust enabled.\"\"\"\n",
    "    global embeddings\n",
    "    embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "def create_vector_database(chunked_documents):\n",
    "    \"\"\"Create a Vector Database Base (VDB) from pre-processed document chunks.\"\"\"\n",
    "    global vectorstore\n",
    "    try:\n",
    "        # Ensure each chunked document is properly structured\n",
    "        wrapped_documents = []\n",
    "        for doc in chunked_documents:\n",
    "            try:\n",
    "                # Directly access page_content and metadata from Document\n",
    "                if not isinstance(doc, Document):\n",
    "                    print(f\"Skipping document with id {doc.id} as it is not a Document object.\")\n",
    "                    continue  # Skip this document if it is not a Document object\n",
    "                \n",
    "                # Append valid Document objects\n",
    "                wrapped_documents.append(doc)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing document with id {doc.id}: {str(e)}\")\n",
    "                continue  # Skip this document if an error occurs\n",
    "\n",
    "        # Create FAISS index and vector embeddings for chunks of data\n",
    "        vectorstore = FAISS.from_documents(wrapped_documents, embeddings)\n",
    "\n",
    "        # Save the vector database index locally\n",
    "        vectorstore.save_local(vectorDB_name)\n",
    "\n",
    "        return \"Successfully created the vector database from chunked documents.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error creating vector database: {str(e)}\"\n",
    "    \n",
    "# Example usage\n",
    "# Step 1: Load documents from a local directory\n",
    "documents_directory = \"/Users/adityavinodh/Documents/sp25mps/raiss_ai/scraped_data_json\"  # Update this to your local directory path\n",
    "chunked_documents = load_documents_from_json(documents_directory)\n",
    "\n",
    "# Step 2: Initialize embeddings model\n",
    "initialize_embeddings()\n",
    "\n",
    "# Step 3: Create the vector database\n",
    "\n",
    "result_message = create_vector_database(chunked_documents)\n",
    "\n",
    "print(result_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c05eeaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:02:05.641250Z",
     "start_time": "2025-04-14T16:02:05.599783Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorstore.save_local(vectorDB_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ff34203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:41:52.422753Z",
     "start_time": "2025-04-14T16:41:51.922497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Query: Tell me about Geneva’s Discoveries to Commercialization\n",
      "\n",
      "📄 doc_0 (source: {'source': 'https://researchservices.cornell.edu/events/weill-institute-special-seminars-2', 'last_modified': '2021-12-01T17:33Z', 'change_frequency': 'never', 'priority': '0.5'}):\n",
      "Find guidance on funding and agency updates during the federal government transition(updated 3/19/2025) (/federal-transition)\n",
      "Essential ToolsFind My GCORASSExternalInstitutional Profile & DUNSIACUC applications (Cayuse Animal Management)Find Your Next Funding OpportunityIBC Applications (RASS-IBC)Re...\n",
      "\n",
      "📄 doc_1 (source: {'source': 'https://researchservices.cornell.edu/process/collaborating-weill-cornell-medicine', 'last_modified': '2019-09-27T16:15Z', 'change_frequency': 'never', 'priority': '0.5'}):\n",
      "Find guidance on funding and agency updates during the federal government transition(updated 3/19/2025) (/federal-transition)\n",
      "Essential ToolsFind My GCORASSExternalInstitutional Profile & DUNSIACUC applications (Cayuse Animal Management)Find Your Next Funding OpportunityIBC Applications (RASS-IBC)Re...\n",
      "\n",
      "📄 doc_2 (source: {'source': 'https://researchservices.cornell.edu/contact/ck554', 'last_modified': '2025-01-21T19:57Z', 'change_frequency': 'yearly', 'priority': '0.5'}):\n",
      "Find guidance on funding and agency updates during the federal government transition(updated 3/19/2025) (/federal-transition)\n",
      "Essential ToolsFind My GCORASSExternalInstitutional Profile & DUNSIACUC applications (Cayuse Animal Management)Find Your Next Funding OpportunityIBC Applications (RASS-IBC)Re...\n",
      "\n",
      "📄 doc_3 (source: {'source': 'https://researchservices.cornell.edu/resources/export-controls-decision-trees', 'last_modified': '2023-04-28T20:08Z', 'change_frequency': 'yearly', 'priority': '0.5'}):\n",
      "Find guidance on funding and agency updates during the federal government transition(updated 3/19/2025) (/federal-transition)\n",
      "Essential ToolsFind My GCORASSExternalInstitutional Profile & DUNSIACUC applications (Cayuse Animal Management)Find Your Next Funding OpportunityIBC Applications (RASS-IBC)Re...\n",
      "[Error] doc_0 relevance check failed: [403] Forbidden\n",
      "Authorization failed\n",
      "[Error] doc_1 relevance check failed: [403] Forbidden\n",
      "Authorization failed\n",
      "[Error] doc_2 relevance check failed: [403] Forbidden\n",
      "Authorization failed\n",
      "[Error] doc_3 relevance check failed: [403] Forbidden\n",
      "Authorization failed\n",
      "Checked 4 docs. Found 0 relevant.\n",
      "No relevant documents found. Skipping final prompt generation.\n",
      "\n",
      "=== Final Answer ===\n",
      "\n",
      "Sorry, I couldn't find a relevant answer in the provided documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "vectorDB_name= \"raiss_site\"\n",
    "\n",
    "def load_vector_database(vectorDB_name = vectorDB_name):\n",
    "    global vectorstore\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.load_local(vectorDB_name, embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "\n",
    "# Example user input\n",
    "user_input = \"Tell me about Geneva’s Discoveries to Commercialization\"\n",
    "\n",
    "# Simulate initial state with only user input\n",
    "state = {\n",
    "    \"user_input\": user_input\n",
    "}\n",
    "\n",
    "# Step 1: Load and search documents dynamically\n",
    "# This adds \"docs\" to the state\n",
    "state = {\n",
    "    **state,\n",
    "    \"docs\": load_and_search_docs(state[\"user_input\"])  # <-- your dynamic search function\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Relevance Filtering via LLM\n",
    "state = check_relevance_node(state)\n",
    "\n",
    "# Step 3: Build Prompt for Final Answer Generation\n",
    "state = build_prompt_node(state)\n",
    "\n",
    "# Step 4: Generate the Answer\n",
    "state = generate_answer_node(state)\n",
    "\n",
    "# Print final output\n",
    "print(\"\\n=== Final Answer ===\\n\")\n",
    "print(state.get(\"answer\", \"[No answer generated]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "513dcb90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:37:30.193088Z",
     "start_time": "2025-04-14T16:37:30.172935Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'FAISS' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(vectorstore[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'FAISS' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(vectorstore[)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
